import streamlit as st
import time
import os 
import base64 
from io import BytesIO 
from typing import List, Dict, Any

# å°è¯•å¯¼å…¥ OpenAI
try:
    from openai import OpenAI
except ImportError:
    st.error("è¯·å…ˆå®‰è£… openai åº“: pip install openai")
    OpenAI = None

# ==========================================
# 1. é¡µé¢é…ç½®ä¸æ ·å¼
# ==========================================
st.set_page_config(
    page_title="èŠå¤©åŠ©æ‰‹ (Chat Coach Pro)",
    page_icon="ğŸ¤–",
    layout="centered"
)

st.markdown("""
<style>
    /* ç»Ÿä¸€è§£æå™¨çš„æ ·å¼ */
    .coach-note {
        background-color: #f7f9fc;
        border-left: 4px solid #4b6cb7;
        padding: 12px;
        border-radius: 4px;
        font-size: 0.9em;
        color: #333;
        margin-top: 8px;
    }
    /* æ‹çˆ±æ¨¡å¼çš„é¢œè‰² (æ¨¡å¼ä¸€) */
    .dating-tag { background-color: #e84393; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; }
    .dating-reply { border: 1px solid #e84393; padding: 10px; border-radius: 8px; margin-bottom: 5px; }
    /* é”€å”®æ¨¡å¼çš„é¢œè‰² (æ¨¡å¼äºŒ) */
    .sales-tag { background-color: #2d3436; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; }
    .sales-reply { border: 1px solid #2d3436; padding: 10px; border-radius: 8px; margin-bottom: 5px; }
    /* æ™®é€šæ¨¡å¼çš„é¢œè‰² (æ¨¡å¼ä¸‰) */
    .normal-tag { background-color: #008c9e; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; }
    .normal-reply { border: 1px solid #008c9e; padding: 10px; border-radius: 8px; margin-bottom: 5px; }
    /* å›å¸–æ¨¡å¼çš„é¢œè‰² (æ¨¡å¼å››) */
    .reply_post-tag { background-color: #f7931e; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; }
    .reply_post-reply { border: 1px solid #f7931e; padding: 10px; border-radius: 8px; margin-bottom: 5px; }
    
    .reply-text {
        font-size: 1.1em;
        font-family: "Microsoft YaHei", sans-serif;
    }
</style>
""", unsafe_allow_html=True)

# å®šä¹‰æ¨¡å‹åˆ—è¡¨å’Œå¤šæ¨¡æ€æ¨¡å‹åç§°
# FIX: ä½¿ç”¨ç”¨æˆ·ç¡®è®¤å¯ç”¨çš„ Qwen å’Œ DeepSeek æ¨¡å‹
TEXT_MODELS = {
    "æ¨è (Qwen2.5)": "Qwen/Qwen2.5-7B-Instruct",
    "DeepSeek-Qwen3": "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    "Qwen2-7B": "Qwen/Qwen2-7B-Instruct",
}
# FIX: å›é€€åˆ° Qwen-VL-Chatï¼Œå› ä¸º Qwen æ–‡æœ¬æ¨¡å‹å¯ç”¨ï¼Œå®ƒæœ€æœ‰å¯èƒ½è¢«ä¿®å¤æˆ–æ‰¾åˆ°æ­£ç¡®åç§°
VISION_MODEL = "Qwen/Qwen-VL-Chat"

# ==========================================
# 2. ä¾§è¾¹æ ï¼šè®¾ç½® (API) - Key æŒä¹…åŒ–ä¸ç¯å¢ƒå˜é‡åŠ è½½
# ==========================================

# é¢„å®šä¹‰å›è°ƒå‡½æ•° (ç”¨äº session_state ä¿æŒ Key)
def save_api_key():
    """å›è°ƒå‡½æ•°ï¼šå°†è¾“å…¥æ¡†çš„å€¼ä¿å­˜åˆ° session_state çš„æŒä¹…åŒ–å˜é‡ä¸­"""
    st.session_state['persisted_api_key'] = st.session_state['api_key_input_key']

# åœ¨ä¾§è¾¹æ ä¸­æ·»åŠ æ¨¡å‹é€‰æ‹©é€»è¾‘
with st.sidebar:
    st.header("âš™ï¸ æ ¸å¿ƒè®¾ç½®")

    # 1. ä¼˜å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– Key
    API_KEY_ENV = os.environ.get("SILICONFLOW_API_KEY")

    if 'persisted_api_key' not in st.session_state:
        st.session_state['persisted_api_key'] = ''
    
    if API_KEY_ENV:
        st.success("ğŸ”‘ API Key å·²ä»ç¯å¢ƒå˜é‡åŠ è½½ã€‚")
        current_api_key = API_KEY_ENV
    else:
        st.warning("ğŸš¨ å»ºè®®é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½® Keyã€‚å½“å‰ä½¿ç”¨è¾“å…¥æ¡†ã€‚")
        
        st.text_input(
            "ğŸ”‘ ç¡…åŸºæµåŠ¨ API Key", 
            type="password",
            value=st.session_state['persisted_api_key'], 
            key="api_key_input_key", 
            on_change=save_api_key
        )
        current_api_key = st.session_state['persisted_api_key']

    st.markdown("---")
    st.subheader("ğŸ§  AI æ¨¡å‹é€‰æ‹©")
    
    # æ¨¡å‹é€‰æ‹©å™¨
    selected_model_key = st.selectbox(
        "é€‰æ‹©æ–‡æœ¬æ¨¡å‹",
        list(TEXT_MODELS.keys()),
        index=0,
        key="model_selector"
    )
    current_text_model = TEXT_MODELS[selected_model_key]

    st.caption(f"å½“å‰æ–‡æœ¬æ¨¡å‹: **{current_text_model}**")
    st.caption(f"å›¾åƒåˆ†ææ¨¡å‹: **{VISION_MODEL}** (ç”¨äºå›¾ç‰‡åˆ†æ)")
    
    st.markdown("---")
    st.markdown("### ğŸ¯ äº§å“ç›®æ ‡")
    st.info("æ¨¡å¼ä¸€: ç¤¾äº¤åŒ¹é…ã€‚\n\næ¨¡å¼äºŒ: å®¢æˆ·è½¬åŒ–ã€‚\n\næ¨¡å¼ä¸‰: æ—¥å¸¸æ²Ÿé€šä¸å†…å®¹ç”Ÿæˆã€‚\n\næ¨¡å¼å››: è®ºå›ä¸ç¤¾åª’äº’åŠ¨ (æ”¯æŒå›¾ç‰‡åˆ†æ)ã€‚") 

# ==========================================
# 3. æ ¸å¿ƒé€»è¾‘å‡½æ•° (å¤šæ¨¡å¼å¤§è„‘)
# ==========================================

def get_system_prompt(main_mode: str, sub_mode: str, extra_detail: str = "") -> str:
    """
    æ ¹æ®æ¨¡å¼ç”Ÿæˆ LLM çš„ç³»ç»ŸæŒ‡ä»¤ã€‚
    :param extra_detail: æ™®é€šæ¨¡å¼ä¸­ä¼ å…¥ 'å…³ç³»'ï¼Œå›å¸–æ¨¡å¼ä¸­ä¼ å…¥ 'å†…å®¹ç±»å‹'ã€‚
    """
    if main_mode == "Dating":
        base_prompt = "ä½ æ˜¯é¡¶çº§æƒ…æ„Ÿé¡¾é—®ï¼Œç²¾é€šæ¨æ‹‰å’Œæš§æ˜§ã€‚å›å¤å¿…é¡»ç®€çŸ­ã€æœ‰è¶£ã€å¸¦æœ‰è°ƒä¾ƒã€‚"
        if sub_mode == "å¼€åœºç™½ç”Ÿæˆ":
            return f"{base_prompt} è¯·æ ¹æ®å¯¹æ–¹çš„ç®€ä»‹ï¼Œç”Ÿæˆ3æ¡èƒ½ç«‹åˆ»æŠ“ä½å¯¹æ–¹å…´è¶£çš„å¼€åœºç™½ã€‚"
        elif sub_mode == "èµ·æ­»å›ç”Ÿæœ¯":
            return f"{base_prompt} å¯¹æ–¹å·²å†·è½ä½ å¾ˆä¹…ï¼Œè¯·ç”Ÿæˆ3æ¡ä½å‹åŠ›ã€é«˜æƒ…ç»ªä»·å€¼çš„æŒ½å›è¯æœ¯ã€‚"
    
    elif main_mode == "Sales":
        base_prompt = "ä½ æ˜¯èµ„æ·±é”€å”®ä¸“å®¶ï¼Œå›å¤å¿…é¡»ä¸“ä¸šã€å†·é™ã€ä»¥å®¢æˆ·ä»·å€¼ä¸ºå¯¼å‘ã€‚"
        if sub_mode == "å®¢æˆ·å¼‚è®®å¤„ç†":
            return f"{base_prompt} å®¢æˆ·æå‡ºäº†å¼‚è®®ï¼Œè¯·ç”Ÿæˆ3ç§ä¸åŒç­–ç•¥çš„å›å¤ï¼š1. ä»·å€¼é”šå®š 2. æƒ…æ„Ÿå…±é¸£ 3. é™æ—¶ä¼˜æƒ ã€‚"
        elif sub_mode == "äº§å“ä»‹ç»æ–‡æ¡ˆ":
            return f"{base_prompt} è¯·æ ¹æ®ä¿¡æ¯ï¼Œç”Ÿæˆ3æ®µé’ˆå¯¹æ€§æå¼ºçš„æ–‡æ¡ˆï¼š1. ç—›ç‚¹åˆ‡å…¥å‹ 2. æƒå¨èƒŒä¹¦å‹ 3. ä½¿ç”¨åœºæ™¯æç»˜å‹ã€‚"
            
    # ====== æ¨¡å¼ä¸‰ï¼šæ™®é€šæ¨¡å¼ (åŸºäºå…³ç³») ======
    elif main_mode == "Normal":
        # extra_detail æ­¤æ—¶æ˜¯å…³ç³» (æœ‹å‹, åŒäº‹, é™Œç”Ÿäºº)
        base_prompt = f"ä½ æ˜¯é«˜æƒ…å•†çš„ä¸‡èƒ½èŠå¤©åŠ©æ‰‹ï¼Œè¯·ä»¥ä¸€ä¸ªé¢å‘'{extra_detail}'çš„èº«ä»½ï¼Œæ ¹æ®ç”¨æˆ·çš„è¾“å…¥ç”Ÿæˆå›å¤ã€‚"
        return f"{base_prompt} è¯·ç”Ÿæˆ3æ¡ä¸åŒä¾§é‡ç‚¹çš„å›å¤ï¼š1. æƒ…æ„Ÿå…±é¸£å¼ 2. ç†æ€§åˆ†æå¼ 3. è½»æ¾å¹½é»˜å¼ã€‚è¯·åœ¨å›å¤å‰æ ‡æ˜é£æ ¼ã€‚"
            
    # ====== æ¨¡å¼å››ï¼šå›å¸–æ¨¡å¼ (åŸºäºå†…å®¹ç±»å‹ï¼Œæ”¯æŒå›¾åƒæè¿°) ======
    elif main_mode == "Reply_Post":
        # extra_detail æ­¤æ—¶æ˜¯å†…å®¹ç±»å‹ (ç½‘å€, æˆªå›¾, è§†é¢‘)
        base_prompt = f"ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç¤¾åª’è¯„è®ºä¸“å®¶ï¼Œæ­£åœ¨é’ˆå¯¹ä¸€ä¸ª'{extra_detail}'ç±»å‹çš„å†…å®¹è¿›è¡Œé«˜è´¨é‡å›å¤ã€‚å¦‚æœæä¾›äº†å›¾ç‰‡ï¼Œè¯·ä¼˜å…ˆåˆ†æå›¾ç‰‡å†…å®¹ã€‚"
        return f"{base_prompt} è¯·ç”Ÿæˆ3æ¡é«˜è´¨é‡çš„è¯„è®ºæˆ–å›å¸–ï¼š1. è§‚ç‚¹è¡¥å……ä¸å‡åå‹ 2. è´¨ç–‘ä¸å¼•å‘è®¨è®ºå‹ 3. æ·±åº¦æ€»ç»“ä¸å½’çº³å‹ã€‚è¯·åœ¨å›å¤å‰æ ‡æ˜é£æ ¼ã€‚"
            
    return "ä½ æ˜¯é«˜æƒ…å•†åŠ©æ‰‹ï¼Œç”Ÿæˆ3æ¡å›å¤å’Œè§£æã€‚"

def parse_ai_response(text, mode):
    """è§£æå™¨ï¼šæ ¹æ®æ¨¡å¼ç»™Tagä¸Šè‰²"""
    results: List[Dict[str, str]] = []
    # å°è¯•å°† DeepSeek æ¨¡å‹å¯èƒ½è¿”å›çš„æ ¼å¼è½¬æ¢ä¸ºæˆ‘ä»¬æœŸæœ›çš„æ ¼å¼
    text = text.replace("é€‰é¡¹ä¸€", "\né€‰é¡¹1").replace("é€‰é¡¹äºŒ", "\né€‰é¡¹2").replace("é€‰é¡¹ä¸‰", "\né€‰é¡¹3")
    parts = text.split("é€‰é¡¹") if "é€‰é¡¹" in text else [text] 
    
    if mode == "Dating":
        css_class = "dating"
    elif mode == "Sales":
        css_class = "sales"
    elif mode == "Normal":
        css_class = "normal"
    elif mode == "Reply_Post":
        css_class = "reply_post" 
    else:
        css_class = "normal"
    
    for part in parts:
        style = "é€šç”¨å›å¤"
        reply = part.strip()
        analysis = "æš‚æ— åˆ†æ"
        
        # ä¼˜åŒ–è§£æé€»è¾‘ä»¥é€‚åº”ä¸åŒæ¨¡å‹çš„è¾“å‡ºé£æ ¼
        if "å›å¤ï¼š" in part and ("ç‚¹è¯„ï¼š" in part or "è§£æï¼š" in part):
            try:
                # å°è¯•æå–é£æ ¼
                style_line = [l for l in part.split("\n") if "é£æ ¼" in l]
                if style_line:
                    style = style_line[0].split("ï¼š")[-1].strip()
                else:
                    style = "N/A"
                
                # æå–å›å¤å’Œç‚¹è¯„
                if "ç‚¹è¯„ï¼š" in part:
                    reply = part.split("å›å¤ï¼š")[1].split("ç‚¹è¯„ï¼š")[0].strip()
                    analysis = part.split("ç‚¹è¯„ï¼š")[1].strip()
                elif "è§£æï¼š" in part: # DeepSeek æ¨¡å‹å¯èƒ½ä¼šä½¿ç”¨â€œè§£æâ€
                    reply = part.split("å›å¤ï¼š")[1].split("è§£æï¼š")[0].strip()
                    analysis = part.split("è§£æï¼š")[1].strip()
            except:
                pass 
        elif "å›å¤ï¼š" in part: 
             try:
                style_line = [l for l in part.split("\n") if "é£æ ¼" in l]
                if style_line:
                    style = style_line[0].split("ï¼š")[-1].strip()
                else:
                    style = "N/A"
                reply = part.split("å›å¤ï¼š")[1].strip()
                analysis = "è¯·è‡ªè¡Œåˆ†æ"
             except:
                pass
        
        if reply: 
            results.append({"style": style, "reply": reply, "analysis": analysis, "css": css_class})
    
    if not results and text.strip():
        results.append({"style": "åŸå§‹å›å¤", "reply": text.strip(), "analysis": "æ ¼å¼æœªèƒ½è¯†åˆ«ï¼Œæ˜¾ç¤ºåŸå§‹å›å¤ã€‚", "css": css_class})

    return results


def get_ai_response(main_mode, sub_mode, input_text, api_key, use_mock=False, extra_detail: str = "", uploaded_image: BytesIO = None, text_model: str = TEXT_MODELS["æ¨è (Qwen2.5)"]):
    """
    æ›´æ–°åçš„ AI å“åº”å‡½æ•°ï¼Œæ”¯æŒå›¾ç‰‡ä¸Šä¼ å’Œæ¨¡å‹é€‰æ‹©ã€‚
    :param text_model: ç”¨æˆ·é€‰æ‹©çš„çº¯æ–‡æœ¬æ¨¡å‹ã€‚
    """
    
    system_prompt_instruction = get_system_prompt(main_mode, sub_mode, extra_detail)

    # --- B. æ¼”ç¤ºæ¨¡å¼ (Mock Data) ---
    if use_mock:
        time.sleep(1)
        if main_mode == "Dating":
            return [{"style": "ğŸ’” èµ·æ­»å›ç”Ÿæœ¯", "reply": "ä½ æœ€è¿‘æ˜¯ä¸æ˜¯åœ¨å¿™ç€æ‹¯æ•‘ä¸–ç•Œï¼Œéƒ½ä¸ç†æˆ‘äº†ï¼Ÿ", "analysis": "å¹½é»˜ä¸”ä¸è¿½é—®çš„è¯•æ¢ï¼Œå·§å¦™åœ°ç»™äº†å°é˜¶ã€‚", "css": "dating"}]
        elif main_mode == "Sales":
            return [{"style": "ğŸ’° ä»·å€¼é”šå®šæ³•", "reply": "æ˜¯çš„ï¼Œä»·æ ¼ç¡®å®ä¸ä½ï¼Œä½†æ‚¨å¾—åˆ°çš„æ˜¯5å¹´çš„ç¨³å®šæœåŠ¡å’Œä¸“å±å”®åï¼Œè¿™èƒ½ä¸ºæ‚¨èŠ‚çœæœªæ¥æ•°ä¸‡å…ƒçš„éšæ€§æˆæœ¬ã€‚", "analysis": "æ‰¿è®¤ä»·æ ¼ï¼Œä½†å°†å®¢æˆ·å…³æ³¨ç‚¹ä»ä»·æ ¼è½¬åˆ°é•¿æœŸæ”¶ç›Šã€‚", "css": "sales"}]
        elif main_mode == "Normal":
            return [{"style": "ğŸ˜€ è½»æ¾å¹½é»˜å¼", "reply": f"ï¼ˆé¢å‘ {extra_detail}ï¼‰è¿™äº‹å„¿å°±è·Ÿç­‰å¤–å–ä¸€æ ·ï¼Œæ€¥ä¹Ÿæ²¡ç”¨ï¼Œä¸å¦‚å…ˆå»æ‰“å±€æ¸¸æˆã€‚", "analysis": "ç”¨æ—¥å¸¸æ¢—ç¼“è§£å‹åŠ›ã€‚", "css": "normal"}]
        elif main_mode == "Reply_Post":
            img_desc = "(å«å›¾ç‰‡å†…å®¹)" if uploaded_image else ""
            return [{"style": "ğŸš€ è§‚ç‚¹å‡åå‹", "reply": f"ï¼ˆé’ˆå¯¹ {extra_detail}{img_desc}ï¼‰è¿™ä¸ªè§‚ç‚¹éå¸¸å…·æœ‰å¯å‘æ€§ï¼Œä½†æˆ‘ä»¬è¿˜å¯ä»¥ä»å¦ä¸€ä¸ªç»´åº¦æ€è€ƒï¼Œå³å…¶é•¿æœŸçš„ç¤¾ä¼šå½±å“ã€‚", "analysis": "åœ¨è‚¯å®šåŸå¸–çš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†æ›´é«˜çš„æ€è€ƒå±‚æ¬¡ã€‚", "css": "reply_post"}]
        return []

    # --- C. çœŸå® AI è°ƒç”¨ ---
    else:
        # ç¡®ä¿ OpenAI åº“å·²å¯¼å…¥
        if OpenAI is None:
            st.error("OpenAI åº“æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ã€‚")
            return []
            
        client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")
        
        model_to_use = text_model
        final_messages = []

        # 1. å¦‚æœæœ‰ä¸Šä¼ å›¾ç‰‡ï¼Œåˆ™å°è¯•ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹ (Vision Model)
        if uploaded_image:
            model_to_use = VISION_MODEL # è¦†ç›–æ–‡æœ¬æ¨¡å‹ï¼Œåˆ‡æ¢åˆ°è§†è§‰æ¨¡å‹
            
            # Base64 ç¼–ç å›¾ç‰‡
            base64_image = base64.b64encode(uploaded_image.getvalue()).decode("utf-8")
            image_url_data = f"data:image/{uploaded_image.type.split('/')[1]};base64,{base64_image}"
            
            # æ„å»ºå¤šæ¨¡æ€ prompt
            full_prompt = f"{system_prompt_instruction}\n\nã€ç”¨æˆ·é¢å¤–æä¾›çš„æ–‡æœ¬ä¿¡æ¯ã€‘ï¼š\"{input_text}\"\n\nè¯·ç»“åˆå›¾ç‰‡å’Œæ–‡æœ¬ä¿¡æ¯ç”Ÿæˆ3ä¸ªé€‰é¡¹ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆçº¯æ–‡æœ¬ï¼‰ï¼š\n\né€‰é¡¹1é£æ ¼ï¼š[ç®€çŸ­é£æ ¼å]\nå›å¤ï¼š[å†…å®¹]\nç‚¹è¯„ï¼š[è§£æ]\n\n(é‡å¤3æ¬¡)"
            
            messages_content = [
                {"type": "text", "text": full_prompt},
                {"type": "image_url", "image_url": {"url": image_url_data}}
            ]
            
            final_messages = [{"role": "user", "content": messages_content}]

        # 2. æ²¡æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„çº¯æ–‡æœ¬æ¨¡å‹
        else:
            full_prompt = f"""
            {system_prompt_instruction}
            
            ã€å¾…å¤„ç†å†…å®¹ã€‘ï¼š"{input_text}"
            
            è¯·ç”Ÿæˆ 3 ä¸ªé€‰é¡¹ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆçº¯æ–‡æœ¬ï¼‰ï¼š
            
            é€‰é¡¹1é£æ ¼ï¼š[ç®€çŸ­é£æ ¼å]
            å›å¤ï¼š[å†…å®¹]
            ç‚¹è¯„ï¼š[è§£æ]
            
            (é‡å¤3æ¬¡)
            """
            final_messages = [{"role": "user", "content": full_prompt}]


        try:
            response = client.chat.completions.create(
                model=model_to_use, 
                messages=final_messages,
                temperature=0.7,
                max_tokens=1500 
            )

            raw_text = response.choices[0].message.content
            return parse_ai_response(raw_text, main_mode)
        except Exception as e:
            # æ•è· API è°ƒç”¨é”™è¯¯ï¼Œå¹¶å‹å¥½æç¤ºç”¨æˆ·
            error_message = f"API è°ƒç”¨å‡ºé”™ (æ¨¡å‹: {model_to_use}): {e}"
            st.error(error_message)
            
            # å¦‚æœæ˜¯å¤šæ¨¡æ€æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œç»™å‡ºæ˜ç¡®æŒ‡å¯¼
            if uploaded_image:
                st.warning(f"âš ï¸ **å›¾ç‰‡åˆ†ææ¨¡å‹è°ƒç”¨å¤±è´¥**ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å½“å‰ä½¿ç”¨çš„æ˜¯ `{VISION_MODEL}`ã€‚å¦‚æœè¯¥æ¨¡å‹æŒç»­å¤±è´¥ï¼Œæ‚¨éœ€è¦**è”ç³»ç¡…åŸºæµåŠ¨å¹³å°**è·å–ä¸€ä¸ª**ç¡®å®šå¯ç”¨**çš„å¤šæ¨¡æ€æ¨¡å‹çš„**ç¡®åˆ‡åç§°**ï¼Œå¹¶æ›¿æ¢ä»£ç ä¸­çš„ `VISION_MODEL` å˜é‡ã€‚")
            else:
                st.warning("âš ï¸ **æ–‡æœ¬æ¨¡å‹è°ƒç”¨å¤±è´¥**ã€‚è¯·æ£€æŸ¥ä¾§è¾¹æ çš„ API Key æ˜¯å¦è¾“å…¥æ­£ç¡®ï¼Œæˆ–å°è¯•åœ¨ä¾§è¾¹æ åˆ‡æ¢åˆ°å…¶ä»– Qwen/DeepSeek æ¨¡å‹ã€‚")
                
            return []

# ==========================================
# 4. ä¸»ç•Œé¢ UI
# ==========================================

st.title("ğŸ¤– èŠå¤©åŠ©æ‰‹")
st.caption("å¤šæ¨¡å¼æ™ºèƒ½å¯¹è¯ä¸å†…å®¹ç”Ÿæˆï¼Œä¸€é”®æå®š") 

tab_dating, tab_sales, tab_normal, tab_reply_post = st.tabs([
    "æ¨¡å¼ä¸€ (æ‹çˆ±è¾…åŠ© AI)", 
    "æ¨¡å¼äºŒ (é”€å”®å®¢æœ AI)",
    "æ¨¡å¼ä¸‰ (æ™®é€šæ¨¡å¼)",    
    "æ¨¡å¼å›› (å›å¸–æ¨¡å¼)"    
])


# --- Tab 1: æ¨¡å¼ä¸€ (æ‹çˆ±è¾…åŠ© AI) ---
with tab_dating:
    st.subheader("ğŸ£ æå‡ä½ çš„ç¤¾äº¤åŒ¹é…ç‡")
    dating_mode = st.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ["å¼€åœºç™½ç”Ÿæˆ", "èµ·æ­»å›ç”Ÿæœ¯"],
        captions=["æ ¹æ®å¯¹æ–¹èµ„æ–™ç”Ÿæˆå¼€åœºç™½", "å¯¹è¯å·²æ­»ï¼ŒæŒ½å›è¯æœ¯"],
        key='dating_mode_radio'
    )
    dating_input_placeholder = "ç²˜è´´å¯¹æ–¹çš„ä¸ªäººç®€ä»‹æ–‡å­—ï¼Œæˆ–ç²˜è´´ä½ ä»¬çš„å†·åœºå¯¹è¯è®°å½•..."
    dating_input = st.text_area("è¾“å…¥å¾…å¤„ç†å†…å®¹", height=150, placeholder=dating_input_placeholder, key='dating_input_text')

    if st.button("ğŸ’˜ ç”Ÿæˆæ‹çˆ±è¯æœ¯", type="primary", key='dating_button'):
        if not dating_input:
            st.warning("è¯·å…ˆè¾“å…¥å†…å®¹ï¼")
        else:
            use_mock = not current_api_key
            
            with st.spinner(f"æ­£åœ¨ä»¥ã€æ‹çˆ±æ¨¡å¼ã€‘ç”Ÿæˆï¼š{dating_mode}..."):
                # ä¼ å…¥é€‰ä¸­çš„æ–‡æœ¬æ¨¡å‹
                results = get_ai_response("Dating", dating_mode, dating_input, current_api_key, use_mock, text_model=current_text_model)
            
            st.markdown("---")
            if use_mock: 
                st.warning("âš ï¸ å½“å‰ Key æœªè®¾ç½®ï¼Œåˆ‡æ¢åˆ°æ¼”ç¤ºæ¨¡å¼ã€‚")
            
            for item in results:
                st.markdown(f"""
                <div class="{item['css']}-reply">
                    <span class="dating-tag">ğŸ¯ {item['style']}</span>
                    <div class='reply-text'>{item['reply']}</div>
                    <div class='coach-note'><b>ğŸ’¡ æŠ€å·§è§£æï¼š</b>{item['analysis']}</div>
                </div>
                """, unsafe_allow_html=True)


# --- Tab 2: æ¨¡å¼äºŒ (é”€å”®å®¢æœ AI) ---
with tab_sales:
    st.subheader("ğŸ“ˆ æé«˜ä½ çš„å®¢æˆ·è½¬åŒ–ç‡")
    sales_mode = st.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ["å®¢æˆ·å¼‚è®®å¤„ç†", "äº§å“ä»‹ç»æ–‡æ¡ˆ"],
        captions=["é’ˆå¯¹æ€§è§£å†³å®¢æˆ·å«Œè´µ/çŠ¹è±«ç­‰é—®é¢˜", "æ ¹æ®ä¿¡æ¯ç”Ÿæˆä¸“ä¸šæ¨å¹¿æ–‡æ¡ˆ"],
        key='sales_mode_radio'
    )
    sales_input_placeholder = "ç²˜è´´å®¢æˆ·çš„å¼‚è®®ï¼ˆæ¯”å¦‚ï¼šå¤ªè´µäº†ï¼Œå†è€ƒè™‘ï¼‰ï¼Œæˆ–ç²˜è´´äº§å“æ ¸å¿ƒä¿¡æ¯..."
    sales_input = st.text_area("è¾“å…¥å¾…å¤„ç†å†…å®¹", height=150, placeholder=sales_input_placeholder, key='sales_input_text')

    if st.button("ğŸ’µ ç”Ÿæˆé”€å”®è¯æœ¯", type="primary", key='sales_button'):
        if not sales_input:
            st.warning("è¯·å…ˆè¾“å…¥å†…å®¹ï¼")
        else:
            use_mock = not current_api_key

            with st.spinner(f"æ­£åœ¨ä»¥ã€é”€å”®æ¨¡å¼ã€‘ç”Ÿæˆï¼š{sales_mode}..."):
                # ä¼ å…¥é€‰ä¸­çš„æ–‡æœ¬æ¨¡å‹
                results = get_ai_response("Sales", sales_mode, sales_input, current_api_key, use_mock, text_model=current_text_model)
            
            st.markdown("---")
            if use_mock: st.warning("âš ï¸ å½“å‰ Key æœªè®¾ç½®ï¼Œåˆ‡æ¢åˆ°æ¼”ç¤ºæ¨¡å¼ã€‚")
            
            for item in results:
                st.markdown(f"""
                <div class="{item['css']}-reply">
                    <span class="sales-tag">ğŸ¯ {item['style']}</span>
                    <div class='reply-text'>{item['reply']}</div>
                    <div class='coach-note'><b>ğŸ’¡ ç­–ç•¥åˆ†æï¼š</b>{item['analysis']}</div>
                </div>
                """, unsafe_allow_html=True)

# --- Tab 3: æ¨¡å¼ä¸‰ (æ™®é€šæ¨¡å¼) ---
with tab_normal:
    st.subheader("ğŸ—£ï¸ æ—¥å¸¸æ²Ÿé€šä¸å†…å®¹ç”Ÿæˆ")
    
    normal_relationship = st.radio(
        "é€‰æ‹©æ²Ÿé€šå¯¹è±¡å…³ç³»",
        ["æœ‹å‹", "åŒäº‹", "é™Œç”Ÿäºº", "å®¶äºº"],
        key='normal_relationship_radio'
    )
    
    normal_input_placeholder = "è¾“å…¥ä½ éœ€è¦ AI å›å¤ã€å»ºè®®æˆ–è¡¨è¾¾çš„å†…å®¹..."
    normal_input = st.text_area("è¾“å…¥å¾…å¤„ç†å†…å®¹", height=150, placeholder=normal_input_placeholder, key='normal_input_text')

    if st.button("ğŸ’¡ ç”Ÿæˆæ™®é€šå›å¤", type="primary", key='normal_button'):
        if not normal_input:
            st.warning("è¯·å…ˆè¾“å…¥å†…å®¹ï¼")
        else:
            use_mock = not current_api_key

            with st.spinner(f"æ­£åœ¨ä»¥ã€æ™®é€šæ¨¡å¼ã€‘ç”Ÿæˆï¼š{normal_relationship} å…³ç³»å›å¤..."):
                # ä¼ å…¥é€‰ä¸­çš„æ–‡æœ¬æ¨¡å‹
                results = get_ai_response("Normal", "æ™®é€šæ¨¡å¼", normal_input, current_api_key, use_mock, normal_relationship, text_model=current_text_model)
            
            st.markdown("---")
            if use_mock: st.warning("âš ï¸ å½“å‰ Key æœªè®¾ç½®ï¼Œåˆ‡æ¢åˆ°æ¼”ç¤ºæ¨¡å¼ã€‚")
            
            for item in results:
                st.markdown(f"""
                <div class="{item['css']}-reply">
                    <span class="normal-tag">ğŸ¯ {item['style']}</span>
                    <div class='reply-text'>{item['reply']}</div>
                    <div class='coach-note'><b>ğŸ’¡ æ€è·¯æ€»ç»“ï¼š</b>{item['analysis']}</div>
                </div>
                """, unsafe_allow_html=True)


# --- Tab 4: æ¨¡å¼å›› (å›å¸–æ¨¡å¼) ---
with tab_reply_post:
    st.subheader("ğŸ’¬ è®ºå›ä¸ç¤¾åª’äº’åŠ¨ä¸“å®¶ (æ”¯æŒå›¾ç‰‡å†…å®¹)")
    
    reply_post_content_type = st.radio(
        "é€‰æ‹©å›å¸–å†…å®¹ç±»å‹",
        ["æ–‡å­—/å¸–å­", "ç½‘å€é“¾æ¥", "æˆªå›¾å†…å®¹", "è§†é¢‘/éŸ³é¢‘å†…å®¹"],
        key='reply_post_content_type_radio'
    )
    
    uploaded_image = None
    if reply_post_content_type == "æˆªå›¾å†…å®¹":
        # æ›´æ–°æç¤ºï¼Œä½¿ç”¨å½“å‰çš„ VISION_MODEL
        st.info(f"è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶è¿›è¡Œåˆ†æã€‚AI å°†å°è¯•è°ƒç”¨å¤šæ¨¡æ€æ¨¡å‹ **{VISION_MODEL}**ã€‚")
        uploaded_image = st.file_uploader(
            "ä¸Šä¼ æˆªå›¾æ–‡ä»¶ (JPG/PNG)", 
            type=["jpg", "jpeg", "png"], 
            key='reply_post_image_uploader'
        )
        if uploaded_image:
            st.image(uploaded_image, caption="å·²ä¸Šä¼ å›¾ç‰‡", use_column_width=True, width=150)
            st.success("å›¾ç‰‡å·²ä¸Šä¼ ï¼ŒAI å°†å°è¯•åˆ†æå›¾ç‰‡å†…å®¹ã€‚")
            reply_post_input_placeholder = "å¯ä»¥è¾“å…¥é¢å¤–æ–‡å­—è¯´æ˜å›¾ç‰‡å†…å®¹..."
        else:
            reply_post_input_placeholder = "è¯·ä¸Šä¼ æˆªå›¾ï¼Œå¹¶è¾“å…¥é¢å¤–æ–‡å­—è¯´æ˜å›¾ç‰‡å†…å®¹..."
    else:
        reply_post_input_placeholder = f"è¾“å…¥å¾…å›å¤çš„å¸–å­æˆ–å¯¹ {reply_post_content_type} çš„æè¿°/æ‘˜è¦..."

    reply_post_input = st.text_area("è¾“å…¥å¾…å›å¤å†…å®¹", height=150, placeholder=reply_post_input_placeholder, key='reply_post_input_text')

    if st.button("âœï¸ ç”Ÿæˆå›å¸–/è¯„è®º", type="primary", key='reply_post_button'):
        if not reply_post_input and not uploaded_image:
            st.warning("è¯·è‡³å°‘è¾“å…¥å†…å®¹æˆ–ä¸Šä¼ å›¾ç‰‡ï¼")
        else:
            use_mock = not current_api_key

            with st.spinner(f"æ­£åœ¨ä»¥ã€å›å¸–æ¨¡å¼ã€‘ç”Ÿæˆï¼š{reply_post_content_type} å›å¤..."):
                # ä¼ å…¥ uploaded_image å’Œ text_model
                results = get_ai_response("Reply_Post", "å›å¸–æ¨¡å¼", reply_post_input, current_api_key, use_mock, reply_post_content_type, uploaded_image, current_text_model)
            
            st.markdown("---")
            if use_mock: st.warning("âš ï¸ å½“å‰ Key æœªè®¾ç½®ï¼Œåˆ‡æ¢åˆ°æ¼”ç¤ºæ¨¡å¼ã€‚")
            
            for item in results:
                st.markdown(f"""
                <div class="{item['css']}-reply">
                    <span class="reply_post-tag">ğŸ¯ {item['style']}</span>
                    <div class='reply-text'>{item['reply']}</div>
                    <div class='coach-note'><b>ğŸ’¡ ç­–ç•¥åˆ†æï¼š</b>{item['analysis']}</div>
                </div>
                """, unsafe_allow_html=True)